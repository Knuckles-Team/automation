# optional for LLaMa flash attention
flash-attn==1.0.4
